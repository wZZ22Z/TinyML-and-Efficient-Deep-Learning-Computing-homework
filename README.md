# TinyML and Efficient Deep Learning Computing Homework

This project is a coursework submission for the **TinyML and Efficient Deep Learning Computing** course, completed using **Google Colab** for implementation. The project explores key topics in TinyML through a series of focused labs.

## Project Overview

The project is divided into four labs, each addressing a critical aspect of TinyML and efficient deep learning:

- **Lab 1**: Focus on **Pruning** – Reducing model size by removing unnecessary parameters while maintaining performance.
- **Lab 2**: Focus on **Quantization** – Applying techniques to reduce model precision for efficient inference.
- **Lab 3**: Focus on **Neural Architecture Search (NAS)** – Automatically discovering optimal model architectures.
- **Lab 4**: Focus on **Quantization of Large Language Models (LLMs)** – Adapting quantization techniques for LLMs to improve efficiency.

## Google Colab for code execution and experimentation.

